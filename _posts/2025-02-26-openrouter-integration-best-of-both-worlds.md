---
layout: post
title: "The Best of Both Worlds: Enclave AI Now Integrates with OpenRouter"
description: "Enclave AI introduces seamless integration with OpenRouter, giving users the flexibility to choose between private local models and powerful cloud-based AI while maintaining the same intuitive interface."
keywords: "OpenRouter integration, Enclave AI, local AI, cloud AI, AI flexibility, private AI, OpenRouter, Hugging Face models, AI choice, hybrid AI approach"
date: 2025-02-26
---

We're excited to announce a groundbreaking update to Enclave AI: seamless integration with [OpenRouter](https://openrouter.ai). This new feature gives you unprecedented flexibility to choose between completely private local models and powerful cloud-based AI optionsâ€”all through the same familiar interface you already know and love.

## Complete AI Flexibility at Your Fingertips

Enclave AI has always been committed to privacy-first, local AI processing. With this update, we're expanding your options while staying true to our core values. Now you can:

- Continue using our collection of optimized local models that run entirely on your device
- Access the latest and most powerful cloud-based models through OpenRouter when you need additional capabilities
- Seamlessly switch between local and cloud processing based on your specific needs

## Why OpenRouter?

[OpenRouter](https://openrouter.ai) serves as a unified API gateway to the world's leading AI models, including those from Anthropic, OpenAI, Google, and many others. By integrating with OpenRouter, we're giving you access to:

- The most powerful frontier models available today
- Specialized models for specific tasks and domains
- A constantly expanding ecosystem of new AI capabilities

## Your Privacy Remains in Your Control

While we're excited to offer cloud options, we understand that privacy is paramount for many of our users. That's why:

- Local processing remains our default and recommended approach
- Cloud processing is completely optional and clearly indicated
- You maintain full control over when and how your data leaves your device
- No data is ever stored or logged without your explicit consent

To understand why keeping AI processing local matters, read our post on [privacy in AI and why local matters](/blog/2024/06/08/privacy-in-ai-why-local-matters/).

## The Same Intuitive Interface

What makes this integration truly special is that it requires no learning curve. Whether you're using a local model or a cloud-based one through OpenRouter, the experience remains consistent:

- The same chat interface you're familiar with
- The same document context features
- The same voice interaction capabilities
- The same Shortcuts integration

Combine this with our [local conversation history](/blog/2025/03/01/conversation-history-local-storage/) feature to keep track of all your interactions across both local and cloud models.

## Practical Applications: Local and Cloud Working Together

This hybrid approach opens up powerful new workflows:

**Initial Private Drafting, Final Cloud Polish**
Draft sensitive documents using local models for complete privacy, then optionally use a cloud model for final refinement when needed.

**Offline Work with Cloud Backup**
Work offline with local models while traveling, then seamlessly switch to cloud models when you have a stable connection and need additional capabilities.

**Privacy-Sensitive Triage**
Use local models for initial processing of sensitive information, only sending non-sensitive portions to cloud models for specialized analysis.

**Adaptive Performance Based on Device Capabilities**
Automatically leverage local models on powerful devices and fall back to cloud options on devices with limited resources.

For even more powerful workflows, learn how to combine these capabilities with our [advanced shortcuts and model selection](/blog/2025/03/09/advanced-shortcuts-model-selection/) feature.

## Important Privacy Notice

With the addition of cloud model capabilities, we've updated our Privacy Policy and Terms of Service to reflect these changes. Key points to be aware of:

- When using cloud models, your conversation data is sent to OpenRouter and the respective model providers
- Cloud model usage is always clearly indicated in the app interface
- Your data handling when using cloud models is subject to OpenRouter's privacy policy and the policies of the model providers
- We've added new sections to our Privacy Policy and Terms of Service specifically addressing third-party services
- You can review our updated policies on our website, including archives of previous versions

We encourage all users to review these updated policies to understand the privacy implications of using cloud models versus local models.

## The Future of AI is Flexible

This integration represents our vision for the future of AI: giving users the power to choose the right tool for each specific task. We believe that the best AI experience combines the privacy and reliability of local processing with the option to access cutting-edge cloud capabilities when needed.

By bridging these two worlds, we're creating an AI assistant that truly adapts to your needs rather than forcing you to adapt to its limitations.

## Looking Forward

As we continue to develop Enclave AI, we remain committed to our founding principles of privacy, user control, and exceptional performance. The OpenRouter integration enhances these values by expanding your options while keeping you in control.

We're excited to see how you'll use this new flexibility in your workflows, and we welcome your feedback as you explore the expanded capabilities.

Ready to experience the best of both worlds? Update Enclave AI today and discover the perfect balance of privacy and power with our new OpenRouter integration. 
